- title: "Accelerating Inference of Masked Image Generators via Reinforcement Learning"
  authors:
    - Pranav Subbaraman
    - Shufan Li
    - Siyan Zhao
    - Aditya Grover
  date: "Nov 30, 2025"
  category: "cs.CV"
  summary: "Masked Generative Models (MGMs) demonstrate strong capabilities in generating high-fidelity images. However, they need many sampling steps to create high-quality generations, resulting in slow inference speed. In this work, we propose Speed-RL, a novel paradigm for accelerating a pretrained MGMs to generate high-quality images in fewer steps. Unlike conventional distillation methods which formulate the acceleration problem as a distribution matching problem, where a few-step student model is trained to match the distribution generated by a many-step teacher model, we consider this problem as a reinforcement learning problem. Since the goal of acceleration is to generate high quality images in fewer steps, we can combine a quality reward with a speed reward and finetune the base model using reinforcement learning with the combined reward as the optimization target. Through extensive experiments, we show that the proposed method was able to accelerate the base model by a factor of 3x while maintaining comparable image quality."
  link: "https://arxiv.org/abs/2511.18191"

- title: "Accelerating Time Series Foundation Models with Speculative Decoding"
  authors:
    - Pranav Subbaraman
    - Fang Sun
    - Yue Yao
    - Huacong Tang
    - Xiao Luo
    - Yizhou Sun
  date: "Nov 22, 2025"
  category: "cs.LG"
  summary: "Modern web applications--from real-time content recommendation and dynamic pricing to CDN optimization--increasingly rely on time-series forecasting to deliver personalized experiences to billions of users. Large-scale Transformer-based models have achieved state-of-the-art performance in time-series forecasting but suffer from high computational costs, limiting their deployment in latency-sensitive web applications. To address this challenge, we propose a general inference acceleration framework that adapts speculative decoding to autoregressive time-series models. Our approach employs a smaller \"draft\" model to propose future time-series patches, which are then verified in parallel by a larger \"target\" model, reducing the number of sequential forward passes required. We address key technical challenges in adapting this technique from discrete language tokens to continuous time-series distributions, including the design of acceptance criteria for multivariate Gaussian patches and practical variants that balance efficiency with accuracy. Through experiments on time series forecasting benchmarks relevant to web applications, we demonstrate significant inference speedups while maintaining competitive accuracy. The framework requires no architectural modifications to existing foundation models, making it immediately applicable to accelerate deployed time-series forecasting systems."
  link: "https://arxiv.org/abs/2512.01094"

